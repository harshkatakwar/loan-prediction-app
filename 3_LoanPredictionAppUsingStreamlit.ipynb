{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "3.LoanPredictionAppUsingStreamlit.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BGsaAghMkAxv"
      },
      "source": [
        "#Loan Prediction Application Using Streamlit"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eEvTRKLwxwFk"
      },
      "source": [
        "##Dataset\n",
        "###Source: \n",
        "https://github.com/mridulrb/Predict-loan-eligibility-using-IBM-Watson-Studio/blob/master/Dataset/train_ctrUa4K.csv\n",
        "###Attribute Information:\n",
        "\n",
        "*   Loan_ID\t- Unique Loan ID\n",
        "*   Gender -\tMale/ Female\n",
        "*   Married\t- Applicant married (Y/N)\n",
        "*   Dependents -\tNumber of dependents\n",
        "*   Education -\tApplicant Education (Graduate/ Not Graduate)\n",
        "*   Self_Employed -\tSelf employed (Y/N)\n",
        "*   ApplicantIncome -\tApplicant income\n",
        "*   CoapplicantIncome -\tCoapplicant income\n",
        "*   LoanAmount -\tLoan amount in thousands\n",
        "*   Loan_Amount_Term -\tTerm of loan in months\n",
        "*   Credit_History - credit history meets guidelines\n",
        "*   Property_Area -\tUrban/Semi Urban/Rural\n",
        "*   Loan_Status -\tLoan approved (Y/N)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tzGVpEA6-C05"
      },
      "source": [
        "## Data Pre-processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GRZ8sU7_iqv3"
      },
      "source": [
        "Loading and visualization of dataset. \n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p2SeAOAqVlnO",
        "outputId": "60f0e907-d744-4070-bacb-7de09459c0d7"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "folder_path='/content/drive/MyDrive/train_ctrUa4K.csv'"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.activity.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fexperimentsandconfigs%20https%3a%2f%2fwww.googleapis.com%2fauth%2fphotos.native&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "4/1AX4XfWg8Dw25LuDT-ClbHS9tTXaMIxecfQNHFa3HvK9-sbhYLhVEoNn9NM0\n",
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "id": "XdIcHf7EdlCG",
        "outputId": "ad01ebbd-048f-4c2b-bc87-9e15ed02ee3f"
      },
      "source": [
        "import pandas as pd\n",
        "train = pd.read_csv(folder_path) \n",
        "train.head()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Loan_ID</th>\n",
              "      <th>Gender</th>\n",
              "      <th>Married</th>\n",
              "      <th>Dependents</th>\n",
              "      <th>Education</th>\n",
              "      <th>Self_Employed</th>\n",
              "      <th>ApplicantIncome</th>\n",
              "      <th>CoapplicantIncome</th>\n",
              "      <th>LoanAmount</th>\n",
              "      <th>Loan_Amount_Term</th>\n",
              "      <th>Credit_History</th>\n",
              "      <th>Property_Area</th>\n",
              "      <th>Loan_Status</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>LP001002</td>\n",
              "      <td>Male</td>\n",
              "      <td>No</td>\n",
              "      <td>0</td>\n",
              "      <td>Graduate</td>\n",
              "      <td>No</td>\n",
              "      <td>5849</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>360.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Urban</td>\n",
              "      <td>Y</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>LP001003</td>\n",
              "      <td>Male</td>\n",
              "      <td>Yes</td>\n",
              "      <td>1</td>\n",
              "      <td>Graduate</td>\n",
              "      <td>No</td>\n",
              "      <td>4583</td>\n",
              "      <td>1508.0</td>\n",
              "      <td>128.0</td>\n",
              "      <td>360.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Rural</td>\n",
              "      <td>N</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>LP001005</td>\n",
              "      <td>Male</td>\n",
              "      <td>Yes</td>\n",
              "      <td>0</td>\n",
              "      <td>Graduate</td>\n",
              "      <td>Yes</td>\n",
              "      <td>3000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>66.0</td>\n",
              "      <td>360.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Urban</td>\n",
              "      <td>Y</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>LP001006</td>\n",
              "      <td>Male</td>\n",
              "      <td>Yes</td>\n",
              "      <td>0</td>\n",
              "      <td>Not Graduate</td>\n",
              "      <td>No</td>\n",
              "      <td>2583</td>\n",
              "      <td>2358.0</td>\n",
              "      <td>120.0</td>\n",
              "      <td>360.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Urban</td>\n",
              "      <td>Y</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>LP001008</td>\n",
              "      <td>Male</td>\n",
              "      <td>No</td>\n",
              "      <td>0</td>\n",
              "      <td>Graduate</td>\n",
              "      <td>No</td>\n",
              "      <td>6000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>141.0</td>\n",
              "      <td>360.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Urban</td>\n",
              "      <td>Y</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    Loan_ID Gender Married  ... Credit_History Property_Area Loan_Status\n",
              "0  LP001002   Male      No  ...            1.0         Urban           Y\n",
              "1  LP001003   Male     Yes  ...            1.0         Rural           N\n",
              "2  LP001005   Male     Yes  ...            1.0         Urban           Y\n",
              "3  LP001006   Male     Yes  ...            1.0         Urban           Y\n",
              "4  LP001008   Male      No  ...            1.0         Urban           Y\n",
              "\n",
              "[5 rows x 13 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OU5QYt5ri9GO"
      },
      "source": [
        "As we know machine learning models take only numbers as inputs and can not process strings. So, we have to deal with the categories present in the dataset and convert them into numbers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-PUlvpw4hE3g"
      },
      "source": [
        "train['Gender']= train['Gender'].map({'Male':0, 'Female':1})\n",
        "train['Married']= train['Married'].map({'No':0, 'Yes':1})\n",
        "train['Loan_Status']= train['Loan_Status'].map({'N':0, 'Y':1})"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n9FUMMpZmwZJ"
      },
      "source": [
        "Next, we check if there are any missing values present in the dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_aLdIJ1PhFiI",
        "outputId": "7e7002a4-0c43-43ba-9029-2e464a765b7a"
      },
      "source": [
        "train.isnull().sum()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Loan_ID               0\n",
              "Gender               13\n",
              "Married               3\n",
              "Dependents           15\n",
              "Education             0\n",
              "Self_Employed        32\n",
              "ApplicantIncome       0\n",
              "CoapplicantIncome     0\n",
              "LoanAmount           22\n",
              "Loan_Amount_Term     14\n",
              "Credit_History       50\n",
              "Property_Area         0\n",
              "Loan_Status           0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HHiJwNejm9mZ"
      },
      "source": [
        "So, there are missing values in the dataset on many variables including the Gender, Married, LoanAmount variable. Next, we will remove all the rows which contain any missing values in them."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cb3VHL5vhPyg",
        "outputId": "fb989cfa-3d6e-4149-f929-97109d96a566"
      },
      "source": [
        "train = train.dropna()\n",
        "train.isnull().sum()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Loan_ID              0\n",
              "Gender               0\n",
              "Married              0\n",
              "Dependents           0\n",
              "Education            0\n",
              "Self_Employed        0\n",
              "ApplicantIncome      0\n",
              "CoapplicantIncome    0\n",
              "LoanAmount           0\n",
              "Loan_Amount_Term     0\n",
              "Credit_History       0\n",
              "Property_Area        0\n",
              "Loan_Status          0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UkL0ZibYnLmS"
      },
      "source": [
        "Now there are no missing values in the dataset. Next, we will separate the dependent (Loan_Status) and the independent variables.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I-NGHr9ahSqa",
        "outputId": "ba485fb2-c8ac-44a1-adfe-d1cac229c32c"
      },
      "source": [
        "# Here we have only picked 5 variables that seemed most relevant to us. These are the Gender, Marital Status, ApplicantIncome, LoanAmount, and \n",
        "# Credit_History\n",
        "# and stored them in variable X. Target variable is stored in another variable y.\n",
        "\n",
        "X = train[['Gender', 'Married', 'ApplicantIncome', 'LoanAmount', 'Credit_History']]\n",
        "y = train.Loan_Status\n",
        "X.shape, y.shape"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((480, 5), (480,))"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-FMenWrr3W3q"
      },
      "source": [
        "##Model Building\n",
        "\n",
        "Here, we will first split our dataset into a training and validation set, so that we can train the model on the training set and evaluate its performance on the validation set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XpEPdeSihWtE"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_cv, y_train, y_cv = train_test_split(X,y, test_size = 0.2, random_state = 10)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jWRB1KVl4D-a"
      },
      "source": [
        "We have split the data using the train_test_split function from the sklearn library keeping the test_size as 0.2 which means 20 percent of the total dataset will be kept aside for the validation set. Next, we will train the random forest model using the training set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b-n4ioHlhXn9",
        "outputId": "c7fac3a0-87b4-4e9d-c524-18af3476b4a9"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier \n",
        "model = RandomForestClassifier(max_depth=4, random_state = 10) \n",
        "model.fit(x_train, y_train)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
              "                       criterion='gini', max_depth=4, max_features='auto',\n",
              "                       max_leaf_nodes=None, max_samples=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
              "                       n_jobs=None, oob_score=False, random_state=10, verbose=0,\n",
              "                       warm_start=False)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bg4eEHrh4KX-"
      },
      "source": [
        "Here, we have kept the max_depth as 4 for each of the trees of our random forest and stored the trained model in a variable named model. Now, our model is trained, let’s check its performance on both the training and validation set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iY8unQcJhZ5X",
        "outputId": "c5e527ce-ecba-4378-f03c-8896c8588848"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "pred_cv = model.predict(x_cv)\n",
        "accuracy_score(y_cv,pred_cv)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8020833333333334"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rPIBWTmy4ZBW"
      },
      "source": [
        "The model is 80% accurate on the validation set. Let’s check the performance on the training set too."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8GDxxieVhdES",
        "outputId": "0b65c558-59e3-4b7f-f1b1-1366d4900777"
      },
      "source": [
        "pred_train = model.predict(x_train)\n",
        "accuracy_score(y_train,pred_train)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8203125"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8WE03iRo5Jb7"
      },
      "source": [
        "Performance on the training set is almost similar to that on the validation set. So, the model has generalized well. Finally, we will save this trained model so that it can be used in the future to make predictions on new observations."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TVVPXA9ihgmE"
      },
      "source": [
        "# saving the model \n",
        "import pickle \n",
        "pickle_out = open(\"classifier.pkl\", mode = \"wb\") \n",
        "pickle.dump(model, pickle_out) \n",
        "pickle_out.close()"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LeEY_Jhu5kWv"
      },
      "source": [
        "We are saving the model in `pickle` format and storing it as `classifier.pkl`. This will store the trained model and we will use this while deploying the model.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2XMaJgkO9rxk"
      },
      "source": [
        "## Model Deployment\n",
        "Necessary installations for deploying the model\n",
        "\n",
        "`pyngrok` is a python wrapper for ngrok which helps to open secure tunnels from public URLs to localhost. This will help us to host our web app.\n",
        "\n",
        "`streamlit` lets you turn data scripts into sharable web apps in minutes, not weeks. It's all Python, open-source, and free! And once you've created an app you can use our free sharing platform to deploy, manage, and share your app with the world.\n",
        "\n",
        "`streamlit_ace` Ace component of streamlit editor."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0GzWWJP5hi5J",
        "outputId": "cb33015b-91f0-4cbb-d109-ad2d9a10ccf3"
      },
      "source": [
        "#Installation\n",
        "!pip install -q pyngrok\n",
        "!pip install -q streamlit\n",
        "!pip install -q streamlit_ace"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l\r\u001b[K     |▍                               | 10 kB 24.1 MB/s eta 0:00:01\r\u001b[K     |▉                               | 20 kB 27.9 MB/s eta 0:00:01\r\u001b[K     |█▎                              | 30 kB 13.0 MB/s eta 0:00:01\r\u001b[K     |█▊                              | 40 kB 9.8 MB/s eta 0:00:01\r\u001b[K     |██▏                             | 51 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██▋                             | 61 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███                             | 71 kB 5.8 MB/s eta 0:00:01\r\u001b[K     |███▌                            | 81 kB 6.5 MB/s eta 0:00:01\r\u001b[K     |████                            | 92 kB 6.8 MB/s eta 0:00:01\r\u001b[K     |████▍                           | 102 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████▉                           | 112 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 122 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 133 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 143 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 153 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████                         | 163 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 174 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████                        | 184 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 194 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 204 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 215 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 225 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 235 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 245 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 256 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 266 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 276 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 286 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 296 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 307 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 317 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 327 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 337 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 348 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 358 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 368 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 378 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 389 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 399 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 409 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 419 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 430 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 440 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 450 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 460 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 471 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 481 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 491 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 501 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 512 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 522 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 532 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 542 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 552 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 563 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 573 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 583 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 593 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 604 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 614 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 624 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 634 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 645 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 655 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 665 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 675 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 686 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 696 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 706 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 716 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 727 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 737 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 745 kB 5.2 MB/s \n",
            "\u001b[?25h  Building wheel for pyngrok (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[K     |████████████████████████████████| 8.3 MB 5.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 111 kB 56.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 76 kB 4.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 4.3 MB 35.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 180 kB 57.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 63 kB 1.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 124 kB 61.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 788 kB 41.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 370 kB 47.8 MB/s \n",
            "\u001b[?25h  Building wheel for blinker (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "jupyter-console 5.2.0 requires prompt-toolkit<2.0.0,>=1.0.0, but you have prompt-toolkit 3.0.20 which is incompatible.\n",
            "google-colab 1.0.0 requires ipykernel~=4.10, but you have ipykernel 6.4.1 which is incompatible.\n",
            "google-colab 1.0.0 requires ipython~=5.5.0, but you have ipython 7.28.0 which is incompatible.\u001b[0m\n",
            "\u001b[K     |████████████████████████████████| 2.6 MB 4.5 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iNXG5qaZYVx2"
      },
      "source": [
        "This is the snippet which will create the application for us."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "knTqJdoVhnAo",
        "outputId": "96aca1e2-5753-4ebe-90b3-400a60bb81f2"
      },
      "source": [
        "# In this part, we are saving the script as app.py, and then we are loading the required libraries which are pickle to \n",
        "# load the trained model and streamlit to build the app. \n",
        "# Then we are loading the trained model and saving it in a variable named classifier.\n",
        "\n",
        "%%writefile app.py\n",
        " \n",
        "import pickle\n",
        "import streamlit as st\n",
        " \n",
        "# loading the trained model\n",
        "pickle_in = open('classifier.pkl', 'rb') \n",
        "classifier = pickle.load(pickle_in)\n",
        " \n",
        "@st.cache()\n",
        "\n",
        "# Here, we have defined the prediction function. This function will take the data provided \n",
        "# by users as input and make the prediction using the model that we have loaded earlier. \n",
        "# It will take the customer details like the gender, marital status, income, loan amount, and credit history as input, \n",
        "# and then pre-process that input so that it can be feed to the model and finally, make the prediction using the model loaded as a classifier. \n",
        "# In the end, it will return whether the loan is approved or not based on the output of the model.\n",
        "  \n",
        "# defining the function which will make the prediction using the data which the user inputs \n",
        "def prediction(Gender, Married, ApplicantIncome, LoanAmount, Credit_History):   \n",
        "    # Pre-processing user input    \n",
        "    if Gender == \"Male\":\n",
        "        Gender = 0\n",
        "    else:\n",
        "        Gender = 1\n",
        "    if Married == \"Unmarried\":\n",
        "        Married = 0\n",
        "    else:\n",
        "        Married = 1\n",
        "    if Credit_History == \"Unclear Debts\":\n",
        "        Credit_History = 0\n",
        "    else:\n",
        "        Credit_History = 1  \n",
        "    LoanAmount = LoanAmount / 1000\n",
        "    # Making predictions \n",
        "    prediction = classifier.predict( \n",
        "        [[Gender, Married, ApplicantIncome, LoanAmount, Credit_History]])\n",
        "    if prediction == 0:\n",
        "        pred = 'Rejected'\n",
        "    else:\n",
        "        pred = 'Approved'\n",
        "    return pred\n",
        "\n",
        "#\n",
        "\n",
        "  \n",
        "# this is the main function in which we define our webpage  \n",
        "def main():       \n",
        "    # front end elements of the web page \n",
        "    html_temp = \"\"\" \n",
        "    <div style =\"background-color:yellow;padding:13px\"> \n",
        "    <h1 style =\"color:black;text-align:center;\">Loan Prediction Application Using Streamlit</h1> \n",
        "    </div> \n",
        "    \"\"\"\n",
        "    # display the front end aspect\n",
        "    st.markdown(html_temp, unsafe_allow_html = True) \n",
        "    # following lines create boxes in which user can enter data required to make prediction \n",
        "    Gender = st.selectbox('Gender',(\"Male\",\"Female\"))\n",
        "    Married = st.selectbox('Marital Status',(\"Unmarried\",\"Married\")) \n",
        "    ApplicantIncome = st.number_input(\"Applicants monthly income\") \n",
        "    LoanAmount = st.number_input(\"Total loan amount\")\n",
        "    Credit_History = st.selectbox('Credit_History',(\"Unclear Debts\",\"No Unclear Debts\"))\n",
        "    result =\"\"\n",
        "    # when 'Predict' is clicked, make the prediction and store it \n",
        "    if st.button(\"Predict\"): \n",
        "        result = prediction(Gender, Married, ApplicantIncome, LoanAmount, Credit_History) \n",
        "        st.success('Your loan is {}'.format(result))\n",
        "        print(LoanAmount)\n",
        "     \n",
        "if __name__=='__main__': \n",
        "    main()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q7wzMiyZd18q"
      },
      "source": [
        "Alright, let’s now host this app to a public URL using `pyngrok` library."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "74p41BANV8AV"
      },
      "source": [
        "!streamlit run app.py &>/dev/null&"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VAwLhjh5jbUj"
      },
      "source": [
        "Here, we are first running the python script. And then we will connect it to a public URL:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2pk8F9pxWQBG",
        "outputId": "9516fc0b-f28f-4447-cd9a-26da0883e8d6"
      },
      "source": [
        "from pyngrok import ngrok\n",
        " \n",
        "public_url = ngrok.connect('8501')\n",
        "public_url"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ""
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<NgrokTunnel: \"http://5e26-35-231-48-174.ngrok.io\" -> \"http://localhost:8501\">"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    }
  ]
}